{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘train/dog’: File exists\n",
      "mkdir: cannot create directory ‘train/cat’: File exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%mkdir \"train/dog\"\n",
    "%mkdir \"train/cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things is to put files into directories by category so I can use DataImageGenerator from keras.  Pretty easy as the category name is in the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dir, subdir, files in os.walk(\"train\"):\n",
    "    if len(subdir) == 0:\n",
    "        continue\n",
    "    for file in files:\n",
    "        category = file.split(\".\")[0]\n",
    "        os.rename(\"{}/{}\".format(dir,file), \"{}/{}/{}\".format(dir, category, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a validation set by picking samples at random and placing them in the validiation folder 'valid'.  Note that this selects images at random only once--a sort of permanent split for the project.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%mkdir \"valid\"\n",
    "%mkdir \"valid/dog\"\n",
    "%mkdir \"valid/cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dogs = [x for x in os.listdir(\"train/dog\")]\n",
    "cats = [x for x in os.listdir(\"train/cat\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "if len(os.listdir(\"valid/dog\")) < 1:\n",
    "    for n in random.sample(range(len(dogs)), 1000):\n",
    "        os.rename(\"train/dog/{}\".format(dogs[n]), \"valid/dog/{}\".format(dogs[n]))\n",
    "\n",
    "if len(os.listdir(\"valid/cat\")) < 1:\n",
    "    for n in random.sample(range(len(cats)), 1000):\n",
    "        os.rename(\"train/cat/{}\".format(cats[n]), \"valid/cat/{}\".format(cats[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the meat of the program.  First I create a generator to stream data into the neural net\n",
    "the train_generator 'generator' can also include commands to flip or rotate images at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE=32\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        rotation_range=30.)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'valid',\n",
    "        target_size=(ROWS, COLS),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the net architecture.\n",
    "2 Convolution layers, first one has 4x4 stide, second 3x3.  16 filters each.\n",
    "Standard pooling (2x2)\n",
    "2 more convolution layers with 32 filters (3x3 stride)\n",
    "Pooling layer\n",
    "Dense layer with 50% dropout (overfitting prevention) \n",
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 4, 4, border_mode='same', input_shape=(ROWS,COLS,CHANNELS),activation='relu'))\n",
    "model.add(Convolution2D(16, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), border_mode='same'))\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), border_mode='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=64, W_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=1, W_regularizer=l2(0.01)))  #binary classification\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run that net! Here I am only using 2000 samples (mainly for speed).  Gives acceptable results in 5 minutes.  Going to all samples provides increased accuracy, but of course, takes much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2016/2000 [==============================] - 26s - loss: 0.9549 - acc: 0.5615    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20\n",
      "2016/2000 [==============================] - 25s - loss: 0.9084 - acc: 0.5615    \n",
      "Epoch 3/20\n",
      "2016/2000 [==============================] - 25s - loss: 0.8052 - acc: 0.5967    \n",
      "Epoch 4/20\n",
      "2016/2000 [==============================] - 25s - loss: 0.7924 - acc: 0.6151    \n",
      "Epoch 5/20\n",
      "2016/2000 [==============================] - 25s - loss: 0.7936 - acc: 0.6181    \n",
      "Epoch 6/20\n",
      "2016/2000 [==============================] - 26s - loss: 0.7764 - acc: 0.6017    \n",
      "Epoch 7/20\n",
      "2016/2000 [==============================] - 26s - loss: 0.7572 - acc: 0.6295    \n",
      "Epoch 8/20\n",
      "2016/2000 [==============================] - 25s - loss: 0.7340 - acc: 0.6225    \n",
      "Epoch 9/20\n",
      "2016/2000 [==============================] - 25s - loss: 0.7142 - acc: 0.6434    \n",
      "Epoch 10/20\n",
      "2008/2000 [==============================] - 24s - loss: 0.6665 - acc: 0.6713    \n",
      "Epoch 11/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6480 - acc: 0.6746    \n",
      "Epoch 12/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6803 - acc: 0.6696    \n",
      "Epoch 13/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6747 - acc: 0.6627    \n",
      "Epoch 14/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6847 - acc: 0.6756    \n",
      "Epoch 15/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.7154 - acc: 0.6726    \n",
      "Epoch 16/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6462 - acc: 0.6885    \n",
      "Epoch 17/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6535 - acc: 0.6766    \n",
      "Epoch 18/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6695 - acc: 0.6905    \n",
      "Epoch 19/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6861 - acc: 0.6835    \n",
      "Epoch 20/20\n",
      "2016/2000 [==============================] - 12s - loss: 0.6799 - acc: 0.6900    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8621fc7cf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])\n",
    "model.fit_generator(generator=train_generator,samples_per_epoch=2000,nb_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid set : 67.05 %\n",
      "--------------------\n",
      "train set : 68.75 %\n"
     ]
    }
   ],
   "source": [
    "print(\"valid set :\", model.evaluate_generator(validation_generator,val_samples=2000)[1]*100, \"%\")\n",
    "print(\"--------------------\")\n",
    "print(\"train set :\", model.evaluate_generator(train_generator,val_samples=2000)[1]*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(train_generator,val_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
