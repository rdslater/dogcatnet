{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘train/dog’: File exists\n",
      "mkdir: cannot create directory ‘train/cat’: File exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%mkdir \"train/dog\"\n",
    "%mkdir \"train/cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dir, subdir, files in os.walk(\"train\"):\n",
    "    if len(subdir) == 0:\n",
    "        continue\n",
    "    for file in files:\n",
    "        category = file.split(\".\")[0]\n",
    "        os.rename(\"{}/{}\".format(dir,file), \"{}/{}/{}\".format(dir, category, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%mkdir \"valid\"\n",
    "%mkdir \"valid/dog\"\n",
    "%mkdir \"valid/cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dogs = [x for x in os.listdir(\"train/dog\")]\n",
    "cats = [x for x in os.listdir(\"train/cat\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "if len(os.listdir(\"valid/dog\")) < 1:\n",
    "    for n in random.sample(range(len(dogs)), 1000):\n",
    "        os.rename(\"train/dog/{}\".format(dogs[n]), \"valid/dog/{}\".format(dogs[n]))\n",
    "\n",
    "if len(os.listdir(\"valid/cat\")) < 1:\n",
    "    for n in random.sample(range(len(cats)), 1000):\n",
    "        os.rename(\"train/cat/{}\".format(cats[n]), \"valid/cat/{}\".format(cats[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE=32\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=(ROWS,COLS),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'valid',\n",
    "        target_size=(ROWS, COLS),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 4, 4, border_mode='same', input_shape=(ROWS,COLS,CHANNELS),activation='relu'))\n",
    "model.add(Convolution2D(4, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), border_mode='same'))\n",
    "model.add(Convolution2D(4, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(4, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), border_mode='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=64, W_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=1, W_regularizer=l2(0.01)))  #binary classification\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "160/160 [==============================] - 2s - loss: 3.0766 - acc: 0.5062     \n",
      "Epoch 2/20\n",
      "160/160 [==============================] - 0s - loss: 1.9629 - acc: 0.5687     \n",
      "Epoch 3/20\n",
      "160/160 [==============================] - 0s - loss: 2.2736 - acc: 0.6000     \n",
      "Epoch 4/20\n",
      "160/160 [==============================] - 0s - loss: 2.0710 - acc: 0.5062     \n",
      "Epoch 5/20\n",
      "160/160 [==============================] - 0s - loss: 1.9150 - acc: 0.5062     \n",
      "Epoch 6/20\n",
      "160/160 [==============================] - 0s - loss: 1.9461 - acc: 0.5500     \n",
      "Epoch 7/20\n",
      "160/160 [==============================] - 0s - loss: 1.8470 - acc: 0.4937     \n",
      "Epoch 8/20\n",
      "160/160 [==============================] - 0s - loss: 1.9715 - acc: 0.6063     \n",
      "Epoch 9/20\n",
      "160/160 [==============================] - 0s - loss: 1.7651 - acc: 0.5438     \n",
      "Epoch 10/20\n",
      "160/160 [==============================] - 0s - loss: 2.0107 - acc: 0.4875     \n",
      "Epoch 11/20\n",
      "160/160 [==============================] - 0s - loss: 1.7785 - acc: 0.5250     \n",
      "Epoch 12/20\n",
      "160/160 [==============================] - 0s - loss: 1.7307 - acc: 0.5625     \n",
      "Epoch 13/20\n",
      "160/160 [==============================] - 0s - loss: 1.7948 - acc: 0.5312     \n",
      "Epoch 14/20\n",
      "160/160 [==============================] - 0s - loss: 1.7496 - acc: 0.4750     \n",
      "Epoch 15/20\n",
      "160/160 [==============================] - 0s - loss: 1.6286 - acc: 0.5812     \n",
      "Epoch 16/20\n",
      "160/160 [==============================] - 0s - loss: 1.6881 - acc: 0.5375     \n",
      "Epoch 17/20\n",
      "160/160 [==============================] - 0s - loss: 1.6616 - acc: 0.5312     \n",
      "Epoch 18/20\n",
      "160/160 [==============================] - 0s - loss: 1.6460 - acc: 0.4937     \n",
      "Epoch 19/20\n",
      "160/160 [==============================] - 0s - loss: 1.5949 - acc: 0.5563     \n",
      "Epoch 20/20\n",
      "160/160 [==============================] - 0s - loss: 1.7475 - acc: 0.4625     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46219e3748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])\n",
    "model.fit_generator(generator=train_generator,samples_per_epoch=160,nb_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"valid set :\", model.evaluate_generator(validation_generator,val_samples=2000)[1]*100, \"%\")\n",
    "print(\"--------------------\")\n",
    "print(\"train set :\", model.evaluate_generator(train_generator,val_samples=2000)[1]*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(train_generator,val_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
